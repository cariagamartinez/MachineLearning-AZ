install.packages("caTools")
# Plantilla para el Pre Procesado de Datos - Datos faltantes
# Importar el dataset
dataset = read.csv('Data.csv')
getwd()
setwd("~/Documents/Cursos Udemy/Matematicas/machinelearning-az/datasets/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------")
# Plantilla para el Pre Procesado de Datos - Datos faltantes
# Importar el dataset
dataset = read.csv('Data.csv')
View(dataset)
# Tratamiento de los valores NA
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
View(dataset)
str(dataset)
# Plantilla para el Pre Procesado de Datos - Datos Categóricos
# Importar el dataset
dataset = read.csv('Data.csv', stringsAsFactors = F)
str(dataset)
# Codificar las variables categóricas
dataset$Country = factor(dataset$Country,
levels = c("France", "Spain", "Germany"),
labels = c(1, 2, 3))
str(dataset)
dataset$Purchased = factor(dataset$Purchased,
levels = c("No", "Yes"),
labels = c(0,1))
str(dataset)
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
View(testing_set)
View(training_set)
# Escalado de valores
training_set[,2:3] = scale(training_set[,2:3])
testing_set[,2:3] = scale(testing_set[,2:3])
install.packages("arules")
library(arules)
setwd("~/Documents/Cursos Udemy/Matematicas/machinelearning-az/datasets/Part 5 - Association Rule Learning/Section 28 - Apriori")
dataset = read.csv("Market_Basket_Optimisation.csv", header = FALSE)
View(dataset)
dataset = read.transactions("Market_Basket_Optimisation.csv",
sep = ",", rm.duplicates = TRUE)
View(dataset)
summary(dataset)
itemFrequencyPlot(dataset, topN = 10)
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.004, confidence = 0.2))
# Visualización de los resultados
inspect(sort(rules, by = 'lift')[1:10])
# Visualización de los resultados
inspect(sort(rules, by = 'lift')[1:10])
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.004, confidence = 0.1))
# Visualización de los resultados
inspect(sort(rules, by = 'lift')[1:10])
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.002, confidence = 0.1))
# Visualización de los resultados
inspect(sort(rules, by = 'lift')[1:10])
install.packages("tinytex")
#Plantilla para el preprocesado de datos
#Importar el dataset
#Creamos también una variable para "guardar" el conjunto de datos.
#Plantilla para el preprocesado de datos
#Importar el dataset
#Creamos también una variable para "guardar" el conjunto de datos.
dataset = read.csv("Data.csv")
#Tratamiento de los valores NA
# Con el signo del dólar podemos acceder a los objetos dentro de la variable dataset (USAR EL TABULADOR).
# Luego nos preguntamos si hay algún NA en la fila de Age y vamos a usar la función ifelse. Esta función ejecuta la primera parte
# del código si la condición es verdadera o bien, la segunda si la condición es falsa.
# La pregunta que haremos a la función ifelse es saber si hay NA en dataset$Age --> is.na (Hay NAs?).
# Si es verdadera se ejecutará lo que haya entre la primera y la segunda coma,
# y si es falso, se ejecuta lo que hay luego de la segunda coma hasta el paréntesis final. Quedaría:
# dataset$Age = ifelse(is.na(dataset$Age), Primera_condicion , Segunda_condicion )
# El primer parámetro será la función ave, que nos permitirá obtener un promedio del factor (columna)
# mediante la función FUN que a cada x, lo reemplaza con la media de la columna, sin incluir los NAs,
# es decir --> na.rm = TRUE. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , Segunda_condicion)
# Si no se encuentra ningún NA, entonces se no se tocaría el código y se mantendría el dataset$Age. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
# Hacemos lo mismo para dataset$salary
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
# Codificar las variables categóricas. En este caso vamos a usar la función factor.
# Esta función representa categorías directamente, por lo que necesita que se indique los levels
# y luego las etiquetas numéricas que se asignen a cada level.
# factor (variable , levels = c(), labels = c())
# En este caso, el programa sabe que la función "factor" representa categorías
# por lo que no es necesario indicar que las etiquetas numéricas no son realmente "números" (que se puedan sumar, etc.)
# Notar que tanto levels como labels son vectores (c)
dataset$Country = factor(dataset$Country,
levels = c("France" , "Spain" , "Germany"),
labels = c(1 , 2 , 3))
# Ahora también hacemos lo mismo con el factor "Purchase" y transformamos a factor 0 el "no" y 1 el "yes"
dataset$Purchased = factor(dataset$Purchased,
levels = c("No" , "Yes"),
labels = c(0 , 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test.
# Vamos a usar caTools
# install.packages("caTools") #Lo he tenido que instalar porque no lo tenía.
# Para cargar la librería usamos library(caTools).
# Como no tenemos la opción de indicar una semilla en la función sample.split, vamos a generarla antes con set.seet(entero)
# En este caso, siempre que usemos la misma semilla, se generará la misma división de datos.
# También vemos que esta función solo acepta la variable a predecir (y = purchased)
# y que el SpliRatio indica la cantidad de datos para entrenamiento (en Python indicamos la cantidad para test).
# Al final, guardamos el return en una variable llamada split
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Como todo sigue guardado en dataset y no se generan nuevas variables, ahora vamos a generar un subconjunto del dataset original
# donde recogeremos los valores en los que la variable split sea TRUE o FALSE y los guardaremos en una nueva variable.
# Así training_set será un subset de dataset y comparará los datos generados por sample.split
# en aquellos que split sea TRUE, serán guardados en training_set y lo mismo con testing_set
training_set = subset (dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores. Nuevamente,la idea es que las variables no dominen sobre las otras.
# Podemos estandarizar o normalizar. Vamos a usar una función del paquete base.
# Pero en este caso tenemos que recordar que solo podemos escalar las columnas numéricas y la columna 1 y 4 son niveles de factor.
# Por eso, ahora vamos a escalar solamente las columnas 2 y 3. Todas las filas se indica con la coma directamente
# (a diferencia que Python que requiere :) y luego indicamos las dos columnas a escalar
training_set[, 2:3] = scale(training_set[, 2:3])
testing_set[, 2:3] = scale(testing_set[, 2:3])
#Plantilla para el preprocesado de datos
#Importar el dataset
#Creamos también una variable para "guardar" el conjunto de datos.
dataset = read.csv("Data.csv")
#Tratamiento de los valores NA
# Con el signo del dólar podemos acceder a los objetos dentro de la variable dataset (USAR EL TABULADOR).
# Luego nos preguntamos si hay algún NA en la fila de Age y vamos a usar la función ifelse. Esta función ejecuta la primera parte
# del código si la condición es verdadera o bien, la segunda si la condición es falsa.
# La pregunta que haremos a la función ifelse es saber si hay NA en dataset$Age --> is.na (Hay NAs?).
# Si es verdadera se ejecutará lo que haya entre la primera y la segunda coma,
# y si es falso, se ejecuta lo que hay luego de la segunda coma hasta el paréntesis final. Quedaría:
# dataset$Age = ifelse(is.na(dataset$Age), Primera_condicion , Segunda_condicion )
# El primer parámetro será la función ave, que nos permitirá obtener un promedio del factor (columna)
# mediante la función FUN que a cada x, lo reemplaza con la media de la columna, sin incluir los NAs,
# es decir --> na.rm = TRUE. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , Segunda_condicion)
# Si no se encuentra ningún NA, entonces se no se tocaría el código y se mantendría el dataset$Age. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
# Hacemos lo mismo para dataset$salary
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
# Codificar las variables categóricas. En este caso vamos a usar la función factor.
# Esta función representa categorías directamente, por lo que necesita que se indique los levels
# y luego las etiquetas numéricas que se asignen a cada level.
# factor (variable , levels = c(), labels = c())
# En este caso, el programa sabe que la función "factor" representa categorías
# por lo que no es necesario indicar que las etiquetas numéricas no son realmente "números" (que se puedan sumar, etc.)
# Notar que tanto levels como labels son vectores (c)
dataset$Country = factor(dataset$Country,
levels = c("France" , "Spain" , "Germany"),
labels = c(1 , 2 , 3))
# Ahora también hacemos lo mismo con el factor "Purchase" y transformamos a factor 0 el "no" y 1 el "yes"
dataset$Purchased = factor(dataset$Purchased,
levels = c("No" , "Yes"),
labels = c(0 , 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test.
# Vamos a usar caTools
# install.packages("caTools") #Lo he tenido que instalar porque no lo tenía.
# Para cargar la librería usamos library(caTools).
# Como no tenemos la opción de indicar una semilla en la función sample.split, vamos a generarla antes con set.seet(entero)
# En este caso, siempre que usemos la misma semilla, se generará la misma división de datos.
# También vemos que esta función solo acepta la variable a predecir (y = purchased)
# y que el SpliRatio indica la cantidad de datos para entrenamiento (en Python indicamos la cantidad para test).
# Al final, guardamos el return en una variable llamada split
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Como todo sigue guardado en dataset y no se generan nuevas variables, ahora vamos a generar un subconjunto del dataset original
# donde recogeremos los valores en los que la variable split sea TRUE o FALSE y los guardaremos en una nueva variable.
# Así training_set será un subset de dataset y comparará los datos generados por sample.split
# en aquellos que split sea TRUE, serán guardados en training_set y lo mismo con testing_set
training_set = subset (dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores. Nuevamente,la idea es que las variables no dominen sobre las otras.
# Podemos estandarizar o normalizar. Vamos a usar una función del paquete base.
# Pero en este caso tenemos que recordar que solo podemos escalar las columnas numéricas y la columna 1 y 4 son niveles de factor.
# Por eso, ahora vamos a escalar solamente las columnas 2 y 3. Todas las filas se indica con la coma directamente
# (a diferencia que Python que requiere :) y luego indicamos las dos columnas a escalar
training_set[, 2:3] = scale(training_set[, 2:3])
testing_set[, 2:3] = scale(testing_set[, 2:3])
dataset = read.csv("Data.csv")
setwd("~/Documents/BIG DATA/@Repositorios/machinelearning-az/datasets/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------")
dataset = read.csv("Data.csv")
#Plantilla para el preprocesado de datos
#Importar el dataset
#Creamos también una variable para "guardar" el conjunto de datos.
dataset = read.csv("Data.csv")
#Tratamiento de los valores NA
# Con el signo del dólar podemos acceder a los objetos dentro de la variable dataset (USAR EL TABULADOR).
# Luego nos preguntamos si hay algún NA en la fila de Age y vamos a usar la función ifelse. Esta función ejecuta la primera parte
# del código si la condición es verdadera o bien, la segunda si la condición es falsa.
# La pregunta que haremos a la función ifelse es saber si hay NA en dataset$Age --> is.na (Hay NAs?).
# Si es verdadera se ejecutará lo que haya entre la primera y la segunda coma,
# y si es falso, se ejecuta lo que hay luego de la segunda coma hasta el paréntesis final. Quedaría:
# dataset$Age = ifelse(is.na(dataset$Age), Primera_condicion , Segunda_condicion )
# El primer parámetro será la función ave, que nos permitirá obtener un promedio del factor (columna)
# mediante la función FUN que a cada x, lo reemplaza con la media de la columna, sin incluir los NAs,
# es decir --> na.rm = TRUE. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , Segunda_condicion)
# Si no se encuentra ningún NA, entonces se no se tocaría el código y se mantendría el dataset$Age. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
# Hacemos lo mismo para dataset$salary
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
# Codificar las variables categóricas. En este caso vamos a usar la función factor.
# Esta función representa categorías directamente, por lo que necesita que se indique los levels
# y luego las etiquetas numéricas que se asignen a cada level.
# factor (variable , levels = c(), labels = c())
# En este caso, el programa sabe que la función "factor" representa categorías
# por lo que no es necesario indicar que las etiquetas numéricas no son realmente "números" (que se puedan sumar, etc.)
# Notar que tanto levels como labels son vectores (c)
dataset$Country = factor(dataset$Country,
levels = c("France" , "Spain" , "Germany"),
labels = c(1 , 2 , 3))
# Ahora también hacemos lo mismo con el factor "Purchase" y transformamos a factor 0 el "no" y 1 el "yes"
dataset$Purchased = factor(dataset$Purchased,
levels = c("No" , "Yes"),
labels = c(0 , 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test.
# Vamos a usar caTools
# install.packages("caTools") #Lo he tenido que instalar porque no lo tenía.
# Para cargar la librería usamos library(caTools).
# Como no tenemos la opción de indicar una semilla en la función sample.split, vamos a generarla antes con set.seet(entero)
# En este caso, siempre que usemos la misma semilla, se generará la misma división de datos.
# También vemos que esta función solo acepta la variable a predecir (y = purchased)
# y que el SpliRatio indica la cantidad de datos para entrenamiento (en Python indicamos la cantidad para test).
# Al final, guardamos el return en una variable llamada split
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Como todo sigue guardado en dataset y no se generan nuevas variables, ahora vamos a generar un subconjunto del dataset original
# donde recogeremos los valores en los que la variable split sea TRUE o FALSE y los guardaremos en una nueva variable.
# Así training_set será un subset de dataset y comparará los datos generados por sample.split
# en aquellos que split sea TRUE, serán guardados en training_set y lo mismo con testing_set
training_set = subset (dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores. Nuevamente,la idea es que las variables no dominen sobre las otras.
# Podemos estandarizar o normalizar. Vamos a usar una función del paquete base.
# Pero en este caso tenemos que recordar que solo podemos escalar las columnas numéricas y la columna 1 y 4 son niveles de factor.
# Por eso, ahora vamos a escalar solamente las columnas 2 y 3. Todas las filas se indica con la coma directamente
# (a diferencia que Python que requiere :) y luego indicamos las dos columnas a escalar
training_set[, 2:3] = scale(training_set[, 2:3])
testing_set[, 2:3] = scale(testing_set[, 2:3])
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
install.packages("survival")
library(ggplot2)
library(knitr)
library(tidyverse)
install.packages("caTools")
#Plantilla para el preprocesado de datos
#Importar el dataset
#Creamos también una variable para "guardar" el conjunto de datos.
dataset = read.csv("Data.csv")
#Tratamiento de los valores NA
# Con el signo del dólar podemos acceder a los objetos dentro de la variable dataset (USAR EL TABULADOR).
# Luego nos preguntamos si hay algún NA en la fila de Age y vamos a usar la función ifelse. Esta función ejecuta la primera parte
# del código si la condición es verdadera o bien, la segunda si la condición es falsa.
# La pregunta que haremos a la función ifelse es saber si hay NA en dataset$Age --> is.na (Hay NAs?).
# Si es verdadera se ejecutará lo que haya entre la primera y la segunda coma,
# y si es falso, se ejecuta lo que hay luego de la segunda coma hasta el paréntesis final. Quedaría:
# dataset$Age = ifelse(is.na(dataset$Age), Primera_condicion , Segunda_condicion )
# El primer parámetro será la función ave, que nos permitirá obtener un promedio del factor (columna)
# mediante la función FUN que a cada x, lo reemplaza con la media de la columna, sin incluir los NAs,
# es decir --> na.rm = TRUE. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , Segunda_condicion)
# Si no se encuentra ningún NA, entonces se no se tocaría el código y se mantendría el dataset$Age. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
# Hacemos lo mismo para dataset$salary
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
# Codificar las variables categóricas. En este caso vamos a usar la función factor.
# Esta función representa categorías directamente, por lo que necesita que se indique los levels
# y luego las etiquetas numéricas que se asignen a cada level.
# factor (variable , levels = c(), labels = c())
# En este caso, el programa sabe que la función "factor" representa categorías
# por lo que no es necesario indicar que las etiquetas numéricas no son realmente "números" (que se puedan sumar, etc.)
# Notar que tanto levels como labels son vectores (c)
dataset$Country = factor(dataset$Country,
levels = c("France" , "Spain" , "Germany"),
labels = c(1 , 2 , 3))
# Ahora también hacemos lo mismo con el factor "Purchase" y transformamos a factor 0 el "no" y 1 el "yes"
dataset$Purchased = factor(dataset$Purchased,
levels = c("No" , "Yes"),
labels = c(0 , 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test.
# Vamos a usar caTools
install.packages("caTools") #Lo he tenido que instalar porque no lo tenía.
# Para cargar la librería usamos library(caTools).
# Como no tenemos la opción de indicar una semilla en la función sample.split, vamos a generarla antes con set.seet(entero)
# En este caso, siempre que usemos la misma semilla, se generará la misma división de datos.
# También vemos que esta función solo acepta la variable a predecir (y = purchased)
# y que el SpliRatio indica la cantidad de datos para entrenamiento (en Python indicamos la cantidad para test).
# Al final, guardamos el return en una variable llamada split
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Como todo sigue guardado en dataset y no se generan nuevas variables, ahora vamos a generar un subconjunto del dataset original
# donde recogeremos los valores en los que la variable split sea TRUE o FALSE y los guardaremos en una nueva variable.
# Así training_set será un subset de dataset y comparará los datos generados por sample.split
# en aquellos que split sea TRUE, serán guardados en training_set y lo mismo con testing_set
training_set = subset (dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores. Nuevamente,la idea es que las variables no dominen sobre las otras.
# Podemos estandarizar o normalizar. Vamos a usar una función del paquete base.
# Pero en este caso tenemos que recordar que solo podemos escalar las columnas numéricas y la columna 1 y 4 son niveles de factor.
# Por eso, ahora vamos a escalar solamente las columnas 2 y 3. Todas las filas se indica con la coma directamente
# (a diferencia que Python que requiere :) y luego indicamos las dos columnas a escalar
training_set[, 2:3] = scale(training_set[, 2:3])
testing_set[, 2:3] = scale(testing_set[, 2:3])
training_set = subset (dataset, split == TRUE)
#Plantilla para el preprocesado de datos
#Importar el dataset
#Creamos también una variable para "guardar" el conjunto de datos.
dataset = read.csv("Data.csv")
#Tratamiento de los valores NA
# Con el signo del dólar podemos acceder a los objetos dentro de la variable dataset (USAR EL TABULADOR).
# Luego nos preguntamos si hay algún NA en la fila de Age y vamos a usar la función ifelse. Esta función ejecuta la primera parte
# del código si la condición es verdadera o bien, la segunda si la condición es falsa.
# La pregunta que haremos a la función ifelse es saber si hay NA en dataset$Age --> is.na (Hay NAs?).
# Si es verdadera se ejecutará lo que haya entre la primera y la segunda coma,
# y si es falso, se ejecuta lo que hay luego de la segunda coma hasta el paréntesis final. Quedaría:
# dataset$Age = ifelse(is.na(dataset$Age), Primera_condicion , Segunda_condicion )
# El primer parámetro será la función ave, que nos permitirá obtener un promedio del factor (columna)
# mediante la función FUN que a cada x, lo reemplaza con la media de la columna, sin incluir los NAs,
# es decir --> na.rm = TRUE. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , Segunda_condicion)
# Si no se encuentra ningún NA, entonces se no se tocaría el código y se mantendría el dataset$Age. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
# Hacemos lo mismo para dataset$salary
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
# Codificar las variables categóricas. En este caso vamos a usar la función factor.
# Esta función representa categorías directamente, por lo que necesita que se indique los levels
# y luego las etiquetas numéricas que se asignen a cada level.
# factor (variable , levels = c(), labels = c())
# En este caso, el programa sabe que la función "factor" representa categorías
# por lo que no es necesario indicar que las etiquetas numéricas no son realmente "números" (que se puedan sumar, etc.)
# Notar que tanto levels como labels son vectores (c)
dataset$Country = factor(dataset$Country,
levels = c("France" , "Spain" , "Germany"),
labels = c(1 , 2 , 3))
# Ahora también hacemos lo mismo con el factor "Purchase" y transformamos a factor 0 el "no" y 1 el "yes"
dataset$Purchased = factor(dataset$Purchased,
levels = c("No" , "Yes"),
labels = c(0 , 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test.
# Vamos a usar caTools
#install.packages("caTools") #Lo he tenido que instalar porque no lo tenía.
# Para cargar la librería usamos library(caTools).
# Como no tenemos la opción de indicar una semilla en la función sample.split, vamos a generarla antes con set.seet(entero)
# En este caso, siempre que usemos la misma semilla, se generará la misma división de datos.
# También vemos que esta función solo acepta la variable a predecir (y = purchased)
# y que el SpliRatio indica la cantidad de datos para entrenamiento (en Python indicamos la cantidad para test).
# Al final, guardamos el return en una variable llamada split
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Como todo sigue guardado en dataset y no se generan nuevas variables, ahora vamos a generar un subconjunto del dataset original
# donde recogeremos los valores en los que la variable split sea TRUE o FALSE y los guardaremos en una nueva variable.
# Así training_set será un subset de dataset y comparará los datos generados por sample.split
# en aquellos que split sea TRUE, serán guardados en training_set y lo mismo con testing_set
training_set = subset (dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores. Nuevamente,la idea es que las variables no dominen sobre las otras.
# Podemos estandarizar o normalizar. Vamos a usar una función del paquete base.
# Pero en este caso tenemos que recordar que solo podemos escalar las columnas numéricas y la columna 1 y 4 son niveles de factor.
# Por eso, ahora vamos a escalar solamente las columnas 2 y 3. Todas las filas se indica con la coma directamente
# (a diferencia que Python que requiere :) y luego indicamos las dos columnas a escalar
training_set[, 2:3] = scale(training_set[, 2:3])
testing_set[, 2:3] = scale(testing_set[, 2:3])
library(caTools)
#Plantilla para el preprocesado de datos
#Importar el dataset
#Creamos también una variable para "guardar" el conjunto de datos.
dataset = read.csv("Data.csv")
#Tratamiento de los valores NA
# Con el signo del dólar podemos acceder a los objetos dentro de la variable dataset (USAR EL TABULADOR).
# Luego nos preguntamos si hay algún NA en la fila de Age y vamos a usar la función ifelse. Esta función ejecuta la primera parte
# del código si la condición es verdadera o bien, la segunda si la condición es falsa.
# La pregunta que haremos a la función ifelse es saber si hay NA en dataset$Age --> is.na (Hay NAs?).
# Si es verdadera se ejecutará lo que haya entre la primera y la segunda coma,
# y si es falso, se ejecuta lo que hay luego de la segunda coma hasta el paréntesis final. Quedaría:
# dataset$Age = ifelse(is.na(dataset$Age), Primera_condicion , Segunda_condicion )
# El primer parámetro será la función ave, que nos permitirá obtener un promedio del factor (columna)
# mediante la función FUN que a cada x, lo reemplaza con la media de la columna, sin incluir los NAs,
# es decir --> na.rm = TRUE. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , Segunda_condicion)
# Si no se encuentra ningún NA, entonces se no se tocaría el código y se mantendría el dataset$Age. Quedaría:
#dataset$Age = ifelse(is.na(dataset$Age),
#               ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
#               , dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
# Hacemos lo mismo para dataset$salary
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
# Codificar las variables categóricas. En este caso vamos a usar la función factor.
# Esta función representa categorías directamente, por lo que necesita que se indique los levels
# y luego las etiquetas numéricas que se asignen a cada level.
# factor (variable , levels = c(), labels = c())
# En este caso, el programa sabe que la función "factor" representa categorías
# por lo que no es necesario indicar que las etiquetas numéricas no son realmente "números" (que se puedan sumar, etc.)
# Notar que tanto levels como labels son vectores (c)
dataset$Country = factor(dataset$Country,
levels = c("France" , "Spain" , "Germany"),
labels = c(1 , 2 , 3))
# Ahora también hacemos lo mismo con el factor "Purchase" y transformamos a factor 0 el "no" y 1 el "yes"
dataset$Purchased = factor(dataset$Purchased,
levels = c("No" , "Yes"),
labels = c(0 , 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test.
# Vamos a usar caTools
#install.packages("caTools") #Lo he tenido que instalar porque no lo tenía.
# Para cargar la librería usamos library(caTools).
# Como no tenemos la opción de indicar una semilla en la función sample.split, vamos a generarla antes con set.seet(entero)
# En este caso, siempre que usemos la misma semilla, se generará la misma división de datos.
# También vemos que esta función solo acepta la variable a predecir (y = purchased)
# y que el SpliRatio indica la cantidad de datos para entrenamiento (en Python indicamos la cantidad para test).
# Al final, guardamos el return en una variable llamada split
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Como todo sigue guardado en dataset y no se generan nuevas variables, ahora vamos a generar un subconjunto del dataset original
# donde recogeremos los valores en los que la variable split sea TRUE o FALSE y los guardaremos en una nueva variable.
# Así training_set será un subset de dataset y comparará los datos generados por sample.split
# en aquellos que split sea TRUE, serán guardados en training_set y lo mismo con testing_set
training_set = subset (dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores. Nuevamente,la idea es que las variables no dominen sobre las otras.
# Podemos estandarizar o normalizar. Vamos a usar una función del paquete base.
# Pero en este caso tenemos que recordar que solo podemos escalar las columnas numéricas y la columna 1 y 4 son niveles de factor.
# Por eso, ahora vamos a escalar solamente las columnas 2 y 3. Todas las filas se indica con la coma directamente
# (a diferencia que Python que requiere :) y luego indicamos las dos columnas a escalar
training_set[, 2:3] = scale(training_set[, 2:3])
testing_set[, 2:3] = scale(testing_set[, 2:3])
install.packages("survival")
