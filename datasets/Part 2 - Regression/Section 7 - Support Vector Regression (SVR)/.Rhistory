bats = sum(AB, na.rm = T),
bat.average = hits / bats
)
batters %>%
filter(bats > 100) %>%
ggplot(mapping = aes(x = bats, y = bat.average))+
geom_point(alpha = 0.2) +
geom_smooth(se = F)
batters %>%
filter(bats > 100) %>%
arrange(desc(bat.average))
# * Medidas de Centralización
not_cancelled %>%
group_by(carrier) %>%
summarise(
mean = mean(arr_delay),
mean2 = mean(arr_delay[arr_delay>0]),
median = median(arr_delay)
)
# * Medidas de dispersión
not_cancelled %>%
group_by(carrier) %>%
summarise(
sd = sd(arr_delay),
iqr = IQR(arr_delay),
mad = mad(arr_delay)
) %>%
arrange(desc(sd))
?mad
# Medidas de orden
not_cancelled %>%
group_by(carrier) %>%
summarise(
first = min(arr_delay),
q1 = quantile(arr_delay, 0.25),
median = quantile(arr_delay, 0.5),## median()
q3 = quantile(arr_delay, 0.75),
last = max(arr_delay)
)
# Medida de posición
not_cancelled %>%
group_by(carrier) %>%
arrange(dep_time) %>%
summarise(
first_dep = first(dep_time),
second_dep = nth(dep_time, 2),
third_dep = nth(dep_time, 3),
last_dep = last(dep_time)
)
not_cancelled %>%
group_by(carrier) %>%
mutate(rank = min_rank(dep_time)) %>%
filter(rank %in% range(rank)) -> temp
View(temp)
# Funciones de conteo
flights %>%
group_by(dest) %>%
summarise(
count = n(),
carriers = n_distinct(carrier),
arrivals = sum(!is.na(arr_delay)),
cancelled = count - arrivals
) %>%
arrange(desc(carriers))
not_cancelled %>% count(dest)
not_cancelled %>% count(tailnum, wt = distance)
## sum /mean de valores lógicos
not_cancelled %>%
group_by(year, month, day) %>%
summarise(n_prior_5 = sum(dep_time < 500))
not_cancelled %>%
group_by(carrier) %>%
summarise(more_than_hour_delay = mean(arr_delay>60)) %>%
arrange(desc(more_than_hour_delay))
## Agrupaciones múltiples
daily <- group_by(flights, year, month, day)
(per_day <- summarise(daily, n_fl = n()))
(per_month <- summarise(per_day, n_fl = sum(n_fl)))
(per_year <- summarise(per_month, n_fl = sum(n_fl)))
business <- group_by(flights, carrier, dest, origin)
summarise(business, n_fl = n()) %>%
summarise(n_fl = sum(n_fl)) %>%
summarise(n_fl = sum(n_fl))
business
business %>%
ungroup() %>%
summarise(n_fl = n())
daily %>%
ungroup() %>%
summarise(n_fl = n())
business %>%
ungroup() %>%
summarise(n_fl = n())
flights %>%
group_by(year, month, day) %>%
filter(rank(desc(arr_delay))<10) -> temp
View(temp)
popular_dest <- flights %>%
group_by(dest) %>%
filter(n()>365)
View(popular_dest)
popular_dest %>%
filter(arr_delay >0) %>%
mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
select (year:day, dest, arr_delay, prop_delay)
View(sorted_date)
View(arrange(flights, desc(distance)))
NA^0
NA|TRUE
NA&FALSE
NA*0
rename(flights, deptime = dep_time,
anio = year, mes = month, dia = day)
View(arrange(flights, desc(distance))[1,])
select(flights, distance, distance)
select(flights, one_of(c("year", "month", "day", "dep_delay", "arr_delay")))
setwd("~/Documents/BIG DATA/MachineLearning_Training/machinelearning-az/datasets/Part 2 - Regression/Section 6 - Polynomial Regression")
# Regresión Polinómica
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ajustar Modelo de Regresión Lineal con el Conjunto de Datos
lin_reg = lm(formula = Salary ~ .,
data = dataset)
# Ajustar Modelo de Regresión Polinómica con el Conjunto de Datos
dataset$Level2 = dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_reg = lm(formula = Salary ~ .,
data = dataset)
# Visualización del modelo lineal
# install.packages("ggplot2")
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción lineal del suedlo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
# Visualización del modelo polinómico
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = x_grid, y = predict(poly_reg,
newdata = data.frame(Level = x_grid,
Level2 = x_grid^2,
Level3 = x_grid^3,
Level4 = x_grid^4))),
color = "blue") +
ggtitle("Predicción polinómica del suedlo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
# Predicción de nuevos resultados con Regresión Lineal
y_pred = predict(lin_reg, newdata = data.frame(Level = 6.5))
# Predicción de nuevos resultados con Regresión Polinómica
y_pred_poly = predict(poly_reg, newdata = data.frame(Level = 6.5,
Level2 = 6.5^2,
Level3 = 6.5^3,
Level4 = 6.5^4))
# Regresión Polinómica
#En este ejemplo, vamos a contratar a un empleado y le vamos a preguntar según su categoría
# qué salario cobraba. Luego veremos en nuestra empresa los datos y generaremos un modelo
# que prediga lo que correspondería cobrar en nuestra empresa.
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3] #Recordar que las columnas empiezan en 1 vamos a quedarnos con la 2 y la 3
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ahora vamos a construir dos modelos: lineal y polinómica
#Ajustar modelo de regresión lineal con el conjunto de datos
lin_reg = lm (formula = Salary ~ .,
data = dataset) # el punto de la fórmula anterior representa "todas las variables"
# En este caso, ver que quiero predecir el salary
# en función del resto de variables
summary(lin_reg)
#Ajustar modelo de regresión polinómica.
# Tenemos que construir primero los términos de la regresión polinómica y crearemos las
# variables con los grados adecuados al polinomio
dataset$Level2 = dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_reg = lm (formula = Salary ~ .,
data = dataset)
summary(poly_reg)
# Visualización del modelo lineal
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción lineal del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#Visualización del modelo polinómico (genera una recta rígida)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción polinómica del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#Visualización del modelo polinómico "mejorado"
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción polinómica del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
View(dataset)
y_pred = predict (lin_reg, newdata = data.frame (Level = 6.5))
View(poly_reg)
View(poly_reg)
y_pred_poly = predict (poly_reg, newdata = data.frame (Level = 6.5,
Level2 = 6.5^2,
Level3 = 6.5^3,
Level4 = 6.5^4))
y_predi_poly = predict (poly_reg, newdata = data.frame (Level = 6.5,
Level2 = 6.5^2,
Level3 = 6.5^3,
Level4 = 6.5^4))
install.packages("e1071")
setwd("~/Documents/BIG DATA/MachineLearning_Training/machinelearning-az/datasets/Part 2 - Regression/Section 7 - Support Vector Regression (SVR)")
setwd("~/Documents/BIG DATA/MachineLearning_Training/machinelearning-az/datasets/Part 2 - Regression/Section 7 - Support Vector Regression (SVR)")
setwd("~/Documents/BIG DATA/MachineLearning_Training/machinelearning-az/datasets/Part 2 - Regression/Section 7 - Support Vector Regression (SVR)")
# SVR
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ajustar SVR con el Conjunto de Datos
#install.packages("e1071") Este es el paquete que vamos a usar para SVR
library(e1071)
library(e1071)
regression = svm(formula = Salary ~ .,
data = dataset,
type = "eps-regression",
kernel = "radial")
View(dataset)
View(regression)
y_pred = predict(regression, newdata = data.frame(Level = 6.5))
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(regression,
newdata = data.frame(Level = dataset$Level))),
color = "blue") +
ggtitle("Predicción (SVR)") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
# SVR
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ajustar SVR con el Conjunto de Datos
#install.packages("e1071") Este es el paquete que vamos a usar para SVR
library(e1071)
regression = svm(formula = Salary ~ .,
data = dataset,
type = "eps-regression",
kernel = "polynomial")
# Predicción de nuevos resultados con SVR
y_pred = predict(regression, newdata = data.frame(Level = 6.5))
# Visualización del modelo de SVR
# install.packages("ggplot2")
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(regression,
newdata = data.frame(Level = dataset$Level))),
color = "blue") +
ggtitle("Predicción (SVR)") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#En este caso el modelo rechazará el valor del sueldo del jefe porque parece ser un
# outlier
# SVR
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ajustar SVR con el Conjunto de Datos
#install.packages("e1071") Este es el paquete que vamos a usar para SVR
library(e1071)
regression = svm(formula = Salary ~ .,
data = dataset,
type = "eps-regression",
kernel = "radial")
# Predicción de nuevos resultados con SVR
y_pred = predict(regression, newdata = data.frame(Level = 6.5))
# Visualización del modelo de SVR
# install.packages("ggplot2")
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(regression,
newdata = data.frame(Level = dataset$Level))),
color = "blue") +
ggtitle("Predicción (SVR)") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#En este caso el modelo rechazará el valor del sueldo del jefe porque parece ser un
# outlier
# SVR
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ajustar SVR con el Conjunto de Datos
#install.packages("e1071") Este es el paquete que vamos a usar para SVR
library(e1071)
regression = svm(formula = Salary ~ .,
data = dataset,
type = "eps-regression",
kernel = "sigmoid")
# Predicción de nuevos resultados con SVR
y_pred = predict(regression, newdata = data.frame(Level = 6.5))
# Visualización del modelo de SVR
# install.packages("ggplot2")
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(regression,
newdata = data.frame(Level = dataset$Level))),
color = "blue") +
ggtitle("Predicción (SVR)") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#En este caso el modelo rechazará el valor del sueldo del jefe porque parece ser un
# outlier
# SVR
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ajustar SVR con el Conjunto de Datos
#install.packages("e1071") Este es el paquete que vamos a usar para SVR
library(e1071)
regression = svm(formula = Salary ~ .,
data = dataset,
type = "eps-regression",
kernel = "lineal")
# Predicción de nuevos resultados con SVR
y_pred = predict(regression, newdata = data.frame(Level = 6.5))
# Visualización del modelo de SVR
# install.packages("ggplot2")
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(regression,
newdata = data.frame(Level = dataset$Level))),
color = "blue") +
ggtitle("Predicción (SVR)") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#En este caso el modelo rechazará el valor del sueldo del jefe porque parece ser un
# outlier
# SVR
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ajustar SVR con el Conjunto de Datos
#install.packages("e1071") Este es el paquete que vamos a usar para SVR
library(e1071)
regression = svm(formula = Salary ~ .,
data = dataset,
type = "eps-regression",
kernel = "linear")
# Predicción de nuevos resultados con SVR
y_pred = predict(regression, newdata = data.frame(Level = 6.5))
# Visualización del modelo de SVR
# install.packages("ggplot2")
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(regression,
newdata = data.frame(Level = dataset$Level))),
color = "blue") +
ggtitle("Predicción (SVR)") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#En este caso el modelo rechazará el valor del sueldo del jefe porque parece ser un
# outlier
# SVR
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ajustar SVR con el Conjunto de Datos
#install.packages("e1071") Este es el paquete que vamos a usar para SVR
library(e1071)
regression = svm(formula = Salary ~ .,
data = dataset,
type = "eps-regression",
kernel = "radial")
# Predicción de nuevos resultados con SVR
y_pred = predict(regression, newdata = data.frame(Level = 6.5))
# Visualización del modelo de SVR
# install.packages("ggplot2")
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(regression,
newdata = data.frame(Level = dataset$Level))),
color = "blue") +
ggtitle("Predicción (SVR)") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#En este caso el modelo rechazará el valor del sueldo del jefe porque parece ser un
# outlier
