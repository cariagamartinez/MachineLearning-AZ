# Crear la matriz de confusión
cm = table(testing_set[, 3], y_pred)
# Visualización del conjunto de entrenamiento
#install.packages("ElemStatLearn")
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualización del conjunto de testing
set = testing_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Conjunto de Testing)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("~/Documents/BIG DATA/@Repositorios/machinelearning-az/datasets/Part 2 - Regression/Section 6 - Polynomial Regression")
# Regresión Polinómica
#En este ejemplo, vamos a contratar a un empleado y le vamos a preguntar según su categoría
# qué salario cobraba. Luego veremos en nuestra empresa los datos y generaremos un modelo
# que prediga lo que correspondería cobrar en nuestra empresa.
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3] #Recordar que las columnas empiezan en 1 vamos a quedarnos con la 2 y la 3
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ahora vamos a construir dos modelos: lineal y polinómica
#Ajustar modelo de regresión lineal con el conjunto de datos
lin_reg = lm (formula = Salary ~ .,
data = dataset) # el punto de la fórmula anterior representa "todas las variables"
# En este caso, ver que quiero predecir el salary
# en función del resto de variables
summary(lin_reg)
#Ajustar modelo de regresión polinómica.
# Tenemos que construir primero los términos de la regresión polinómica y crearemos las
# variables con los grados adecuados al polinomio
dataset$Level2 = dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_reg = lm (formula = Salary ~ .,
data = dataset)
summary(poly_reg)
# Visualización del modelo lineal
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción lineal del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#Visualización del modelo polinómico (genera una recta rígida)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción polinómica del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#Visualización del modelo polinómico "mejorado" (genera una línea más contínua)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción polinómica del compra de prendas relacionadas") +
xlab("Prenda A") +
ylab("Prenda B")
# Predicción de nuevos resultados con la regresión lineal: un único número
# En este caso, R necesita un data frame con el dato a predecir, así que creamos un
# nuevo data frame con un único valor y dentro la columna Level
y_pred = predict (lin_reg, newdata = data.frame (Level = 6.5))
#Predicción de nuevos resultados con la regresión polinómica. Recordemos que ahora
# necesitamos suministrar todos los datos para la predicción ya que el modelo requiere
# los datos de la columas level2, level3, level4, etc., que en todos los casos es el
# cuadrado, cubo, potencia cuarta, etc, del valor a predecir
y_predi_poly = predict (poly_reg, newdata = data.frame (Level = 6.5,
Level2 = 6.5^2,
Level3 = 6.5^3,
Level4 = 6.5^4))
# Regresión Polinómica
#En este ejemplo, vamos a contratar a un empleado y le vamos a preguntar según su categoría
# qué salario cobraba. Luego veremos en nuestra empresa los datos y generaremos un modelo
# que prediga lo que correspondería cobrar en nuestra empresa.
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3] #Recordar que las columnas empiezan en 1 vamos a quedarnos con la 2 y la 3
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ahora vamos a construir dos modelos: lineal y polinómica
#Ajustar modelo de regresión lineal con el conjunto de datos
lin_reg = lm (formula = Salary ~ .,
data = dataset) # el punto de la fórmula anterior representa "todas las variables"
# En este caso, ver que quiero predecir el salary
# en función del resto de variables
summary(lin_reg)
#Ajustar modelo de regresión polinómica.
# Tenemos que construir primero los términos de la regresión polinómica y crearemos las
# variables con los grados adecuados al polinomio
dataset$Level2 = dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_reg = lm (formula = Salary ~ .,
data = dataset)
summary(poly_reg)
# Visualización del modelo lineal
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción lineal del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#Visualización del modelo polinómico (genera una recta rígida)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción polinómica del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#Visualización del modelo polinómico "mejorado" (genera una línea más contínua)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción polinómica del compra de prendas relacionadas") +
xlab("Prenda A") +
ylab("Prenda B")
# Predicción de nuevos resultados con la regresión lineal: un único número
# En este caso, R necesita un data frame con el dato a predecir, así que creamos un
# nuevo data frame con un único valor y dentro la columna Level
y_pred = predict (lin_reg, newdata = data.frame (Level = 6.5))
#Predicción de nuevos resultados con la regresión polinómica. Recordemos que ahora
# necesitamos suministrar todos los datos para la predicción ya que el modelo requiere
# los datos de la columas level2, level3, level4, etc., que en todos los casos es el
# cuadrado, cubo, potencia cuarta, etc, del valor a predecir
y_predi_poly = predict (poly_reg, newdata = data.frame (Level = 6.5,
Level2 = 6.5^2,
Level3 = 6.5^3,
Level4 = 6.5^4))
library(dplyr)
library(ggplot2)
library(tidyverse)
# Regresión Polinómica
#En este ejemplo, vamos a contratar a un empleado y le vamos a preguntar según su categoría
# qué salario cobraba. Luego veremos en nuestra empresa los datos y generaremos un modelo
# que prediga lo que correspondería cobrar en nuestra empresa.
# Importar el dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[, 2:3] #Recordar que las columnas empiezan en 1 vamos a quedarnos con la 2 y la 3
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# training_set = subset(dataset, split == TRUE)
# testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# training_set[,2:3] = scale(training_set[,2:3])
# testing_set[,2:3] = scale(testing_set[,2:3])
# Ahora vamos a construir dos modelos: lineal y polinómica
#Ajustar modelo de regresión lineal con el conjunto de datos
lin_reg = lm (formula = Salary ~ .,
data = dataset) # el punto de la fórmula anterior representa "todas las variables"
# En este caso, ver que quiero predecir el salary
# en función del resto de variables
summary(lin_reg)
#Ajustar modelo de regresión polinómica.
# Tenemos que construir primero los términos de la regresión polinómica y crearemos las
# variables con los grados adecuados al polinomio
dataset$Level2 = dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_reg = lm (formula = Salary ~ .,
data = dataset)
summary(poly_reg)
# Visualización del modelo lineal
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción lineal del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#Visualización del modelo polinómico (genera una recta rígida)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción polinómica del sueldo en función del nivel del empleado") +
xlab("Nivel del empleado") +
ylab("Sueldo (en $)")
#Visualización del modelo polinómico "mejorado" (genera una línea más contínua)
ggplot() +
geom_point(aes(x = dataset$Level , y = dataset$Salary),
color = "red") +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
color = "blue") +
ggtitle("Predicción polinómica del compra de prendas relacionadas") +
xlab("Prenda A") +
ylab("Prenda B")
# Predicción de nuevos resultados con la regresión lineal: un único número
# En este caso, R necesita un data frame con el dato a predecir, así que creamos un
# nuevo data frame con un único valor y dentro la columna Level
y_pred = predict (lin_reg, newdata = data.frame (Level = 6.5))
#Predicción de nuevos resultados con la regresión polinómica. Recordemos que ahora
# necesitamos suministrar todos los datos para la predicción ya que el modelo requiere
# los datos de la columas level2, level3, level4, etc., que en todos los casos es el
# cuadrado, cubo, potencia cuarta, etc, del valor a predecir
y_predi_poly = predict (poly_reg, newdata = data.frame (Level = 6.5,
Level2 = 6.5^2,
Level3 = 6.5^3,
Level4 = 6.5^4))
#Data Visualization - 11 de Mayo de 2018
library(tidyverse)
# tidyverse 1.3.0 ──
# ✓ ggplot2 3.3.0     ✓ purrr   0.3.4
# ✓ tibble  3.0.1     ✓ dplyr   0.8.5
# ✓ tidyr   1.0.3     ✓ stringr 1.4.0
# ✓ readr   1.3.1     ✓ forcats 0.5.0
#Los coches con motor más grande consumen más combustible
#que los coches con motor más pequeño.
#La relación consumo / tamaño es lineal? Es no lineal? Es exponencial?
#Es positiva? Es negativa?
View(mpg)
?mpg #help(mpg)
# displ: tamaño del motor del coche en litros
# hwy: número de millas recorridas en autopista por galón de combustible (3.785411784 litros)
ggplot(data = mpg)
mpg %>% ggplot()
#PLANTILLA PARA HACER UNA REPRESENTACIÓN GRÁFICA CON GGPLOT
#ggplot(data = datos_a_representar) +
#  geom_function(mapping = aes(<MAPPINGS>))   --> Los mappings son parámetros para modificar el gráfico
#aes es la función que tiene que ver con la estética = aesthetic = propiedad visual
ggplot(data = mpg) +  # Se inicia llamando a la función ggplot y se crea un gráfico vacío, solo sabiendo qué set usará. El (+) agrega una capa.
geom_point(mapping = aes(x = displ, y = hwy)) # Añade la capa de puntos para el gráfico
# Vamos a generar un gráfico donde el color de las marcas dependerá de cada variable
# En este caso, en el dataset mpg hay una columna que indica la "clase del coche"
# que se llama class --> la asignaremos al color, en este caso, la variable
# color puede ser en inglés americano o británico (color = colour)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, color = class))
# Ahora vamos a "mapear" el tamaño de los puntos, según la categoría
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, size = class))
# Ahora podríamos usar la estética de alfa para gestionar la opacidad/ transparencia
# para eso se usa el parámetro alpha.
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, alpha = class))
# Ahora podríamos cambiar la forma de los puntos. Sin embargo, ggplot no puede
# manejar más de 6 formas a la vez.
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ,
y = hwy,
shape = class)
)
# También podemos elegir directamente las estéticas. Observar que está fuera del
# mapping, lo cual daría una estética global. Por ejemplo:
# Nombre del color en formato string = "xx"
#  size = tamaño del punto en mm
# shape = forma del punto con números desde el 0 al 25
# ggplot(data = mpg)+
#   geom_point(mapping = aes(x=displ, y=hwy), color = "red")
#
# d=data.frame(p=c(0:25))
# ggplot() +
#   scale_y_continuous(name="") +
#   scale_x_continuous(name="") +
#   scale_shape_identity() +
#   geom_point(data=d, mapping=aes(x=p%%16, y=p%/%16, shape=p), size=5, fill="yellow") +
#   geom_text(data=d, mapping=aes(x=p%%16, y=p%/%16+0.25, label=p), size=3)
# Si quisiéramos hacer un gráfico de cada una de las variables, o para divivir el
# gráfico en subgráficos, haremos un facet. En este caso, vamos a usar la
# variable del tipo de coche (class) y que se vea en 2 filas
# FACETS y se usa así:
# facets_wrap (~<Formula_variable>): la variable debe ser discreta
ggplot(data = mpg) +
geom_point (mapping = aes(x= displ,
y = hwy)) +
facet_wrap(~class, nrow = 2)
# También podríamos usar un facet para combinar 2 variables y se usa facet_grid
# facets_grid (<Formula_variable_1>~<Formula_variable_2>).
# Por ejemplo, vamos ha hacer un gráfico donde se evalúen todos los x=displ vs y=hwy
# pero separados según su tipo de tracción (drv) y su cilindrada (cyl).
# Así, el gráfico sigue siendo el mismo (displ vs hwy) pero los puntos se han separado
# según su tipo de tracción y su cilindrada
ggplot (data = mpg) +
geom_point(mapping = aes (x = displ,
y = hwy)) +
facet_grid(drv~cyl)
# En este caso, podemos ver que los facets y los geom_points son independiente
# se le pueden agregar parámetro por separado. Por ejemplo, que le un color
ggplot(data = mpg) +
geom_point (mapping = aes(x= displ,
y = hwy,
color = class)) +
facet_grid(drv~cyl)
# Si usamos el punto antes o después de la variable, tenemos la división según el eje
# pero únicamente con la variable indicada
ggplot(data = mpg) +
geom_point (mapping = aes(x= displ,
y = hwy)) +
facet_grid(.~cyl) # división del grid pone a la variable cyl paralela al eje y.
##
ggplot(data = mpg) +
geom_point (mapping = aes(x= displ,
y = hwy)) +
facet_grid(drv~.) # En este caso, la división del grid pone a la variable drv paralela al eje x.
# Diferentes geometrías
ggplot(data = mpg) +
geom_point (mapping = aes(x= displ,
y = hwy))
ggplot(data = mpg) +
geom_smooth (mapping = aes(x= displ,
y = hwy))
ggplot(data = mpg) +
geom_smooth (mapping = aes(x= displ,
y = hwy,
linetype = drv, #linetype indica qué variable separará
color = drv)) # color indica la variable que coloreará
ggplot(data = mpg) +
geom_smooth (mapping = aes(x= displ,
y = hwy,
linetype = drv, #linetype indica qué variable separar
color = drv)) # en este caso, usamos la tracción (drv)
# También podríamos combinar ambas capas de la geom_smooth y la geom_point.
# Tendríamos puntos de colores según tracción y luego
# tendríamos una línea según la tracción y un color según dicha tracción.
# Esta sería una combinación donde veríamos todos los datos y luego la línea de tendencia,
# en ambos casos con los colores coincidentes
ggplot(data = mpg) +
geom_point (mapping = aes(x = displ,
y = hwy,
color = drv)) +
geom_smooth (mapping = aes(x= displ,
y = hwy,
linetype = drv,
color = drv))
##
ggplot(data = mpg) +
geom_smooth (mapping = aes(x= displ,
y = hwy,
group = drv, #solo agrupa, pero no cambia el tipo de línea
color = drv),
show.legend = T) # Fuerza la aparición de la leyenda
# Vemos que siempre tenemos que estar planteando los mappings, así que podríamos
# plantearlos de manera global en lugar de en cada una de las capas y luego eliminarlos
# del resto de las capas.
# Pero podríamos crear un mapping local, que predomina sobre el global
ggplot(data = mpg, mapping = aes(x= displ, y = hwy))+
geom_point(mapping = aes (color = class))+
geom_smooth(mapping = aes(color=drv))
# Aquí tenemos mappings globales y luego haremos un mapping local para colorear por tipo de coche (class)
# Luego usaremos una capa de geom_smooth y filtraremos los datos del dataset mpg
# para quedarnos solamente con aquellos cuya tipo sea suv (class == "suv")
# Al hacer se = F se eliminará el color gris alrededor de la curva (confianza)
ggplot(data = mpg, mapping = aes(x=displ, y = hwy)) +
geom_point(mapping = aes(color = class)) +
geom_smooth(data = filter(mpg, class == "suv"), se = F)
# Tarea 7
ggplot(data = mpg, mapping = aes(x=displ, y = hwy,color = drv)) +
geom_point() +
geom_smooth( se = F)
# Tarea 5
ggplot(data = mpg, mapping = aes(x=displ, y = hwy)) +
geom_point() +
geom_smooth( se = F)
# Tarea 6
ggplot(data = mpg, mapping = aes(x=displ, y = hwy)) +
geom_point() +
geom_smooth(mapping = (aes(group = drv)), se = F)
# Vamos a cambiar de dataset para ver otro con más variables para
# generar un diagrama de barras. El dataset es diamonds.
diamonds
View(diamonds)
ggplot(data=diamonds) +
geom_bar(mapping = aes(x=cut)) # Aquí solo ponemos una variable discreta
ggplot(data = diamonds)+
stat_count(mapping = aes(x=cut, color=cut, fill = cut))
ggplot(data = diamonds)+
stat_count(mapping = aes(x=cut))
# Vamos a usar un tribble que hace una selección de datos fijos y lo guardamos en la
# variable demo_diamonds que tiene datos guardados en ~cut y en ~freqs
demo_diamonds <- tribble(
~cut,       ~freqs,
"Fair",       1610,
"Good",       4906,
"Very Good", 12082,
"Premium",   13791,
"Ideal",     21551
)
ggplot(data = demo_diamonds) +
geom_bar(mapping = aes(x=cut, y = freqs),
stat = "identity") # "identity" suministra la x y la y,
# en lugar de que haga un contaje del dataset
# Vamos a ver ahora la proporción, usando una proporción stat implícita
# usando ..prop.. y agrupadas en la X(group = 1)
ggplot(data = diamonds)+
geom_bar(mapping = (aes(x=cut, y = ..prop.., group =1)))
ggplot(data = diamonds)+
stat_summary (mapping = aes(x = cut, y = price),
fun.ymin = min,
fun.ymax = max,
fun.y = median
)
#Tarea 5
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1))
# Falta el group = 1
# Se puede hacer un diagrama apilado con:
ggplot(data = diamonds)+
geom_bar(mapping = aes(x=cut, fill = cut))
ggplot(data = diamonds)+
geom_bar(mapping = aes(x=cut, fill = clarity))
ggplot(data = diamonds)+
geom_bar(mapping = aes(x=cut, fill = color))
# Si no se quiere esta opción, podemos usar otra variable
## position = "identity", así todas las barras empiezan abajo
ggplot(data = diamonds, mapping = aes(x=cut, fill = clarity))+
geom_bar(position = "identity")
## position = "fill" hace que todas las barras sean de la misma altura y sirve para
# comparar proporciones
ggplot(data = diamonds, mapping = aes(x=cut, fill = clarity))+
geom_bar(position = "fill")
# position = "dodge" pone las barras con overlapping una al lado de la otra
ggplot(data = diamonds, mapping = aes(x=cut, fill = clarity))+
geom_bar(position = "dodge")
#Problema del overplotting. Cuando vemos puntos, es posible que muchos coincidan en un
# solo lugar, pero realmente es posible que muchos coincidan en el mismo lugar.
# Para evitar eso, vamos a usar el parámetro jitter, que nos permitirá ver mejor
# cómo están los puntos. Jitter agregará un ligero ruido aleatorio para ver mejor los
# puntos. Solo tiene sentido en los scatters plots
ggplot (data = mpg, mapping = aes(x=displ, y=hwy))+
geom_point(position = "jitter")
ggplot (data = mpg, mapping = aes(x=displ, y=hwy))+
geom_jitter()
#Sistemas de coordenadas
#coord_flip() -> cambia la orientación de x e y
ggplot(data = mpg, mapping = aes(x=class, y = hwy))+
geom_boxplot()+
coord_flip() #giramos el gráfico
#coord_quickmap() -> configura el aspect ratio para mapas
install.packages("maps")
usa <- map_data("usa")
ggplot(usa, aes(long, lat, group = group))+
geom_polygon(fill = "blue", colour ="white")+
coord_quickmap()
italy <- map_data("italy")
ggplot(italy, aes(long, lat, group = group))+
geom_polygon(fill = "blue", colour ="white")+
coord_quickmap()
# coord_polar()
ggplot(data = diamonds)+
geom_bar(mapping = aes(x=cut, fill =cut),
show.legend = F,
width = 1)+
theme(aspect.ratio = 1)+
labs(x=NULL, y=NULL)+
coord_polar()
# Gráfica por capas
#PLANTILLA PARA HACER UNA REPRESENTACIÓN GRÁFICA CON GGPLOT
#ggplot(data = <DATA_FRAME>) +
# #  <GEOM_FUNCTION>(
#                     mapping = aes(<MAPPINGS>),
#                     stat = <STATS>
#                     position = <POSITION>
#                     ) +
#   <COORDINATE_FUNCTION>()+
#   <FACET_FUNCTION>()
ggplot(data = mpg) +
geom_point (mapping = aes(x= displ,
y = hwy, ylabel = "Prenda A")) +
facet_grid(drv~.)
